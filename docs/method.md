---
layout: default
title: Method
nav_order: 4
has_children: false
permalink: /docs/method
---

# Method

---

Our approach to real-time garbage segmentation involves an end-to-end pipeline, incorporating automated image annotation, classification, and semantic segmentation. This cohesive pipeline pivots around two stages: data preprocessing and model training. Our choice of semantic segmentation over instance segmentation is governed by the practicality of real-life waste management scenarios, where it is not beneficial to further segregate garbage of identical types, as they would get disposed into the same trash bin. In real-life deployment scenarios where sensors and cameras performance are limited [20], it becomes imperative to optimally balance processing efficiency with the computational expense [18]. Hence, the crux of our methodology is the generation of a high-quality garbage dataset coupled with a focus on an equilibrium between our model's efficiency and its accuracy. This approach empowers our model to not only achieve superior performance metrics but also remain pragmatically feasible for real-time deployment in diverse and complex waste management environments.

## Data Preprocessing

To address the model's bias towards a specific class of garbage, we implemented downsampling on classes that had a significant number of samples (e.g., clothes, shoes). This involved reducing the number of samples in these classes to approximately 700 images each, resulting in a training dataset of approximately 8,000 images. We recognized the dual importance of dataset quality and quantity in training robust garbage segmentation models. Manual annotation, while ensuring accuracy, poses challenges in terms of labor intensity and scalability, hence requiring an automated solution. To address this, we conducted a rigorous investigation, experimenting with different techniques to streamline the annotation process. We found a solution to automate the annotation process and expedite it using a combination of the Grounding DINO and the Segment Anything Model (SAM). This innovative data preprocessing approach not only reduced the workload but also maintained the high quality of our dataset. By automating the labor-intensive aspects of data preparation, we ensured our dataset's balance and integrity, which are critical factors in building effective garbage segmentation models. See Figure 2 for a sample from the annotated dataset.

In the data preprocessing stage, we first applied the Grounding DINO technique to perform Zero-Shot Object Detection on our dataset encompassing 12 distinct categories of garbage [11]. Grounding DINO excels at detecting objects even when confronted with objects that do not align with the predefined set of classes in the training data. This unique capability enables the model to adapt to novel objects and scenarios, rendering it highly versatile and relevant for subsequent garbage segmentation tasks.

Subsequently, the detected bounding boxes generated by the Grounding DINO technique were utilized to prompt SAM for the purpose of conducting instance segmentation on the input images [9]. Given the extensive diversity and irregular spatial distribution of garbage in the real world, the adoption of instance segmentation through SAM presents a notable advantage by isolating each individual piece of garbage. This isolation ensures a more precise classification and segmentation in subsequent steps.

In order to achieve a seamless integration of SAM and Grounding DINO, and to potentially involve human tuning in the annotation results, the Roboflow API was utilized. This API facilitates the storage and inspection of annotated images, while also enabling the incorporation of more fine-grained human adjustments on imperfect annotations. The integration of this API resulted in enhanced efficiency and effectiveness of the data preprocessing pipeline, leading to further improvements in our dataset quality.

Also, various data augmentation techniques were employed to improve the model's ability to learn from data effectively. Resizing, random cropping, and several affine transformations (e.g., horizontal flip, rotation) were applied to introduce variations in the training set. Additionally, resizing and normalizations are applied to ensure all images have the same dimensions and similar pixel value distributions before being fed into the model. For validation and training sets, similar resizing and normalization are performed but without any random transformations to preserve the original data integrity.

## Model Training

In the model training stage, we compared the performances of different backbones (MobileNetV3, ResNet50) and heads (FCN, DeepLabv3) for our real-time garbage segmentation task. We utilized the labeled dataset generated during the preprocessing stage as an input for these models. The role of the backbones in this process was to extract relevant features, which formed the basis for distinguishing different types of waste. Our decision to adopt the ResNet50 architecture stems from its capacity to learn residual mappings and train deep neural networks, and its proven effectiveness across various computer vision tasks such as image classification, object detection, and image segmentation made it a solid choice for our classification training task, which directly impacts the performance of subsequent segmentation tasks [5]. Alongside ResNet50, we trained MobileNetV3, an architecture known for its optimization in speed and size. Its efficiency makes it highly suitable for mobile and edge devices, lending versatility to our project.

For the downstream semantic segmentation task, we employed DeepLabv3, a model recognized for its exceptional performance in semantic segmentation. DeepLabv3 incorporates dilated convolutions and atrous spatial pyramid pooling (ASPP) to capture multi-scale context [2]. It expands the receptive field of filters using dilated convolutions, enabling the model to process a larger context without escalating computational complexity. Each unit in the output of this layer is a weighted sum of all units in the corresponding location across all input channels, which can be thought of as integrating the multi-scale context information. As a result, it provides a finer segmentation result by considering the context of the objects, allowing it to distinguish garbage from the surroundings accurately.

## Baseline Comparison

We have implemented a straightforward baseline method for comparing performances across different backbone and head combinations. Initially, we employed the Grounding DINO technique and the SAM model for data preprocessing, following the same procedure described earlier. Subsequently, we utilized a pretrained ResNet50 model as a backbone to extract features from the preprocessed dataset, capturing both visual and textual information. Lastly, we used a simple fully connected network as the head, which yields moderate accuracy and efficiency. This combined approach allows for the analysis and comparison to evaluate the similarity or dissimilarity of data samples within the given task, providing a fundamental baseline for our model's assessment. On top of that, we fine-tuned different variations of pretrained ResNet50 [5] and MobileNetV3 [6] to compare both accuracy and efficiency of various state-of-the-art models.

