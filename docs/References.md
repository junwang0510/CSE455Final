---
layout: default
title: References
nav_order: 7
has_children: false
permalink: /docs/references
---
# References

---
[1] Rahmi A. Aral, Seref R. Keskin, Mahmut Kaya, and Murat Hacıomerog lu. Classification of trashnet dataset based on deep learning models. In *2018 IEEE International Conference on Big Data (Big Data)*, page 2058–2062, 2018.

[2] Liang-Chieh Chen, George Papandreou, Florian Schroff, and Hartwig Adam. Rethinking atrous convolution for semantic image segmentation. In *arXiv preprint arXiv:1706.05587*, 2017.

[3] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. In *arXiv preprint arXiv:1610.02357*, 2016.

[4] Kai Han, An Xiao, Enhua Wu, Jianyuan Guo, Chunjing Xu, and Yunhe Wang. Transformer in transformer. In *arXiv preprint arXiv:2103.00112*, 2021.

[5] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In *CVPR*, 2016.

[6] Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen, Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan, Quoc V. Le, and Hartwig Adam. Searching for mobilenetv3. In *arXiv preprint arXiv:1905.02244*, 2019.

[7] Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. In *arXiv preprint arXiv:1704.04861*, 2017.

[8] Gao Huang, Zhuang Liu, Laurens van der Maaten, and Kilian Q. Weinberger. Densely connected convolutional networks. In *arXiv preprint arXiv:1608.06993*, 2016.

[9] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C. Berg, Wan-Yen Lo, Piotr Dollar, and Ross Girshick. Segment anything. In *arXiv preprint arXiv:2304.02643*, 2023.

[10] Jiacai Liao, Libo Cao, Wei Li, Xiexing Feng, Jianhua Li, and Feng Yuan. Road garbage segmentation and cleanliness assessment based on semantic segmentation network for cleaning vehicles. In *IEEE Trans. Veh. Technol.*, 2021.

[11] Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao Zhang, Jie Yang, Chunyuan Li, Jianwei Yang, Hang Su, Jun Zhu, and Lei Zhang. Grounding dino: Marrying dino with grounded pre-training for open-set object detection. In *arXiv preprint arXiv:2303.05499*, 2023.

[12] Ze Liu, Yutong Lin, Yue Cao, Han Hu, Yixuan Wei, Zheng Zhang, Stephen Lin, and Baining Guo. Swin transformer: Hierarchical vision transformer using shifted windows. *2021 IEEE/CVF International Conference on Computer Vision (ICCV)*, pages 9992–10002, 2021.

[13] Ilya Loshchilov and Frank Hutter. Decoupled weight decay regularization. In *International Conference on Learning Representations*, 2017.

[14] Sachin Mehta and Mohammad Rastegari. Mobilevit: Lightweight, general-purpose, and mobile-friendly vision transformer. In *arXiv preprint arXiv:2110.02178*, 2022.

[15] Shanshan Meng and W. Chu. A study of garbage classification with convolutional neural networks. In *2020 Indo–Taiwan 2nd International Conference on Computing, Analytics and Networks (Indo-Taiwan ICAN)*, pages 152–157, 2020.

[16] Mostafa Mohamed. Garbage classification (12 classes), 2021. Accessed: 2023-04-24.

[17] Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, and Alex Alemi. Inception-v4, inception-resnet and the impact of residual connections on learning. In *arXiv preprint arXiv:1602.07261*, 2016.

[18] Yanping Tan, Wei Guo, Ke Yang, Jingjing Huang, and Zhengping Yang. Design of intelligent garbage classification system based on internet of things technology. *Journal of Physics: Conference Series*, 2187, 2022.

[19] Wenguan Wang, Tianfei Zhou, Fisher Yu, Jifeng Dai, Ender Konukoglu, and Luc Van Gool. Exploring cross-image pixel contrast for semantic segmentation. *2021 IEEE/CVF International Conference on Computer Vision (ICCV)*, pages 7283–7293, 2021.

[20] Xianjun Yi, Yinyi Liang, and Hongchi Peng. Garbage classification system based on artificial intelligence and internet of things. *2022 International Conference on Artificial Intelli- gence and Computer Information Technology (AICIT)*, pages 1–5, 2022.
